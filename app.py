import streamlit as st
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
import tempfile
import os

# Streamlit page configuration
st.set_page_config(
    page_title="PDF “õ“±–∂–∞—Ç–ø–µ–Ω “õ–∞–∑–∞“õ—à–∞ —Å”©–π–ª–µ—Å—É",
    page_icon="üìö",
    layout="wide"
)

# Custom CSS for better UI
st.markdown("""
    <style>
    .stApp {
        max-width: 1200px;
        margin: 0 auto;
    }
    .css-1d391kg {
        padding: 2rem 1rem;
    }
    .stButton>button {
        width: 100%;
    }
    </style>
    """, unsafe_allow_html=True)

# Title and description
st.title("üìö PDF “õ“±–∂–∞—Ç–ø–µ–Ω “õ–∞–∑–∞“õ—à–∞ —Å”©–π–ª–µ—Å—É")
st.markdown("PDF “õ“±–∂–∞—Ç—Ç–∞—Ä—ã“£—ã–∑–±–µ–Ω “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ —Å”©–π–ª–µ—Å—ñ“£—ñ–∑. –ö–µ–∑-–∫–µ–ª–≥–µ–Ω —Ç—ñ–ª–¥–µ–≥—ñ PDF “õ“±–∂–∞—Ç—Ç–∞—Ä“ì–∞ “õ–∞–∑–∞“õ—à–∞ —Å“±—Ä–∞“õ “õ–æ—è –∞–ª–∞—Å—ã–∑.")

# Initialize session state
if 'conversation' not in st.session_state:
    st.session_state.conversation = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'suggested_questions' not in st.session_state:
    st.session_state.suggested_questions = []

# API key input
api_key = st.text_input("OpenAI API –∫—ñ–ª—Ç—ñ–Ω –µ–Ω–≥—ñ–∑—ñ“£—ñ–∑:", type="password")

def process_pdf(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    # Load and split the PDF
    loader = PyPDFLoader(tmp_file_path)
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    documents = text_splitter.split_documents(documents)

    # Create embeddings and vector store
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vectorstore = FAISS.from_documents(documents, embeddings)

    # Create conversation chain
    llm = ChatOpenAI(
        temperature=0.7,
        model_name='gpt-4',
        openai_api_key=api_key
    )
    memory = ConversationBufferMemory(
        memory_key='chat_history',
        return_messages=True
    )
    
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory,
    )

    # Clean up temp file
    os.unlink(tmp_file_path)
    
    return conversation_chain

def generate_suggested_questions(context):
    if not api_key:
        return []
    
    llm = ChatOpenAI(temperature=0.7, openai_api_key=api_key)
    prompt = f"""
    –ë–µ—Ä—ñ–ª–≥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ–≥—ñ–∑—ñ–Ω–¥–µ 3 —ã“õ—Ç–∏–º–∞–ª —Å“±—Ä–∞“õ “±—Å—ã–Ω—ã“£—ã–∑. 
    –°“±—Ä–∞“õ—Ç–∞—Ä “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ –±–æ–ª—É—ã –∫–µ—Ä–µ–∫.
    –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}
    """
    response = llm.predict(prompt)
    questions = [q.strip() for q in response.split('\n') if q.strip()]
    return questions[:3]

# File upload
uploaded_file = st.file_uploader("PDF “õ“±–∂–∞—Ç—Ç—ã –∂“Ø–∫—Ç–µ“£—ñ–∑", type="pdf")

if uploaded_file and api_key:
    if not st.session_state.conversation:
        with st.spinner("“ö“±–∂–∞—Ç ”©“£–¥–µ–ª—É–¥–µ..."):
            st.session_state.conversation = process_pdf(uploaded_file)
        st.success("“ö“±–∂–∞—Ç —Å”ô—Ç—Ç—ñ –∂“Ø–∫—Ç–µ–ª–¥—ñ!")

# Chat interface
if st.session_state.conversation:
    # Chat input
    user_question = st.text_input("–°“±—Ä–∞“ì—ã“£—ã–∑–¥—ã “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ –∂–∞–∑—ã“£—ã–∑:")
    
    # Suggested questions buttons
    if st.session_state.suggested_questions:
        st.write("–´“õ—Ç–∏–º–∞–ª —Å“±—Ä–∞“õ—Ç–∞—Ä:")
        cols = st.columns(len(st.session_state.suggested_questions))
        for i, question in enumerate(st.session_state.suggested_questions):
            if cols[i].button(question):
                user_question = question

    if user_question:
        with st.spinner("–ñ–∞—É–∞–ø —ñ–∑–¥–µ—É–¥–µ..."):
            response = st.session_state.conversation({
                'question': f"""
                –°“±—Ä–∞“õ“õ–∞ “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ –∂–∞—É–∞–ø –±–µ—Ä—ñ“£—ñ–∑. 
                –ï–≥–µ—Ä “õ“±–∂–∞—Ç—Ç–∞ –∂–∞—É–∞–ø —Ç–∞–±—ã–ª–º–∞—Å–∞, –æ–Ω—ã –∞–π—Ç—ã“£—ã–∑.
                –°“±—Ä–∞“õ: {user_question}
                """
            })
            
            # Store chat history
            st.session_state.chat_history.append((user_question, response['answer']))
            
            # Generate new suggested questions
            st.session_state.suggested_questions = generate_suggested_questions(response['answer'])

# Display chat history
for question, answer in st.session_state.chat_history:
    st.write(f"üôã‚Äç‚ôÇÔ∏è **–°“±—Ä–∞“õ:** {question}")
    st.write(f"ü§ñ **–ñ–∞—É–∞–ø:** {answer}")
    st.markdown("---")

# Footer
st.markdown("""
---
–ë“±–ª –±–∞“ì–¥–∞—Ä–ª–∞–º–∞–Ω—ã –∂–∞—Å–∞“ì–∞–Ω –¢–∏–º—É—Ä –ë–µ–∫—Ç“±—Ä. 
–ï–≥–µ—Ä —Å—ñ–∑ –¥–µ –∂–∞—Å–∞–Ω–¥—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∞—Ä“õ—ã–ª—ã –±–∞“ì–¥–∞—Ä–ª–∞–º–∞ –∂–∞—Å–∞—É–¥—ã “Ø–π—Ä–µ–Ω–≥—ñ“£—ñ–∑ –∫–µ–ª—Å–µ, 
”©–∑–≥–µ –¥–µ –∏–¥–µ—è–ª–∞—Ä –±–æ–π—ã–Ω—à–∞ –ñ–ò –∞—Ä“õ—ã–ª—ã ”©–∑—ñ“£—ñ–∑–≥–µ “õ–æ—Å—ã–º—à–∞ –∂–∞—Å–∞“ì—ã“£—ã–∑ –∫–µ–ª—Å–µ, 
–º–∞“ì–∞–Ω —Ö–∞–±–∞—Ä–ª–∞—Å—ã“£—ã–∑: instagram @timurbektur
""")
